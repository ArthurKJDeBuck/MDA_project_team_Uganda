{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project1=pd.read_parquet(\"aed_locations.parquet.gzip\")\n",
    "mda_project2=pd.read_parquet(\"interventions2.parquet.gzip\")\n",
    "mda_project3=pd.read_parquet(\"interventions3.parquet.gzip\")\n",
    "mda_project4=pd.read_parquet(\"interventions_bxl.parquet.gzip\")\n",
    "mda_project5=pd.read_parquet(\"interventions_bxl2.parquet.gzip\")\n",
    "mda_project7=pd.read_parquet(\"ambulance_locations.parquet.gzip\")\n",
    "mda_project6=pd.read_parquet(\"cad9.parquet.gzip\")\n",
    "mda_project8=pd.read_parquet(\"mug_locations.parquet.gzip\")\n",
    "mda_project9=pd.read_parquet(\"pit_locations.parquet.gzip\")\n",
    "mda_project10=pd.read_parquet(\"interventions1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the data types\n",
    "\n",
    "print(mda_project8.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mda_project3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_project9.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mda_project6['EventType Trip'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mda_project10['EventType Firstcall'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mda_project2['EventType Firstcall'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mda_project3['EventType Firstcall'].unique().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join interventions1_cardiac, interventions2_cardiac, and interventions3_cardiac into a single dataframe\n",
    "interventions_cardiac = pd.concat([mda_project10, mda_project2, mda_project3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "mda_project6.rename(columns={'Mission ID':'Mission ID', 'Service Name':'Service Name', 'Latitude permanence': 'Latitude Permanence', 'Longitude permanence': 'Longitude Permanence', 'Latitude intervention': 'Latitude Intervention', 'Longitude intervention': 'Longitude Intervention', 'Vector Type':'Vector Type'}, inplace=True)\n",
    "interventions_cardiac.rename(columns={'Mission ID':'Mission ID', 'Service Name':'Service Name', 'Latitude permanence': 'Latitude Permanence', 'Longitude permanence': 'Longitude Permanence', 'Latitude intervention': 'Latitude Intervention', 'Longitude intervention': 'Longitude Intervention', 'Vector type':'Vector Type', 'Abandon reason':'Abandon Reason'}, inplace=True)\n",
    "mda_project5.rename(columns={'Mission ID':'Mission ID', 'Service Name NL':'Service Name', 'Latitude permanence': 'Latitude Permanence', 'Longitude permanence': 'Longitude Permanence', 'Latitude intervention': 'Latitude Intervention', 'Longitude intervention': 'Longitude Intervention', 'Vector type NL':'Vector Type', 'Abandon reason NL':'Abandon Reason'}, inplace=True)\n",
    "mda_project4.rename(columns={'mission_id':'Mission ID', 'service_name':'Service Name', 'latitude_permanence': 'Latitude Permanence', 'longitude_permanence':'Longitude Permanence', 'latitude_intervention':'Latitude Intervention', 'longitude_intervention':'Longitude Intervention', 'vector_type':'Vector Type', 't0':'T0', 't1':'T1', 't2':'T2', 't3':'T3', 't4':'T4', 't5':'T5', 't6':'T6', 'abandon_reason':'Abandon Reason'}, inplace=True)\n",
    "#print(interventions_cardiac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_cardiac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date/time strings to pandas datetime objects (this operation is realized in several step, dependent on the time stamp, due to the non-uniformity of the data even within the different time stamps)\n",
    "mda_project6['T0'] = pd.to_datetime(mda_project6['T0'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "interventions_cardiac['T0'] = pd.to_datetime(interventions_cardiac['T0'], format='%d%b%y:%H:%M:%S')\n",
    "mda_project5['T0'] = pd.to_datetime(mda_project5['T0'], format='%d%b%y:%H:%M:%S')\n",
    "mda_project4['T0'] = mda_project4['T0'].astype(str).str[:19]\n",
    "mda_project4['T0'] = pd.to_datetime(mda_project4['T0'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "mda_project6['T1'] = pd.to_datetime(mda_project6['T1'], format='%d%b%y:%H:%M:%S')\n",
    "interventions_cardiac['T1'] = pd.to_datetime(interventions_cardiac['T1'], format='%d%b%y:%H:%M:%S')\n",
    "mda_project5['T1'] = pd.to_datetime(mda_project5['T1'], format='%d%b%y:%H:%M:%S')\n",
    "mda_project4['T1'] = mda_project4['T1'].astype(str).str[:19]\n",
    "mda_project4['T1'] = pd.to_datetime(mda_project4['T1'], format='%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "times_steps = ['T2', 'T3', 'T4', 'T5', 'T6']\n",
    "for time_step in times_steps:\n",
    "    mda_project6[time_step] = mda_project6[time_step].astype(str).str[:19]\n",
    "    mda_project6[time_step] = pd.to_datetime(mda_project6[time_step], format='%Y-%m-%d %H:%M:%S', errors= 'coerce')\n",
    "    interventions_cardiac[time_step] = interventions_cardiac[time_step].astype(str).str[:19]\n",
    "    interventions_cardiac[time_step] = pd.to_datetime(interventions_cardiac[time_step], format='%Y-%m-%d %H:%M:%S', errors ='coerce')\n",
    "    mda_project5[time_step] = pd.to_datetime(mda_project5[time_step], format='%d%b%y:%H:%M:%S')\n",
    "    mda_project4[time_step] = mda_project4[time_step].astype(str).str[:19]\n",
    "    mda_project4[time_step] = pd.to_datetime(mda_project4[time_step], format='%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "# Add a new column 'Abandon Reason' to cad9_cardiac with value 'Overleden', and also overwrite the interventions_bxl2_cardiac with the same (maybe some issue with the filtering earlier??)\n",
    "mda_project6['Abandon Reason'] = 'Overleden'\n",
    "mda_project5['Abandon Reason'] = 'Overleden'\n",
    "\n",
    "# Add a new column to track the original file\n",
    "mda_project6['Original File'] = 'cad9_cardiac'\n",
    "interventions_cardiac['Original File'] = 'interventions_cardiac'\n",
    "mda_project4['Original File'] = 'mda_project4'\n",
    "mda_project5['Original File'] = 'mda_project5'\n",
    "\n",
    "# Concatenate all dataframes\n",
    "frames = [\n",
    "    mda_project6[['Mission ID', 'Service Name', 'Latitude Permanence', 'Longitude Permanence', 'Latitude Intervention', 'Longitude Intervention', 'Vector Type', 'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'Abandon Reason', 'Original File']], \n",
    "    interventions_cardiac[['Mission ID', 'Service Name', 'Latitude Permanence', 'Longitude Permanence', 'Latitude Intervention', 'Longitude Intervention', 'Vector Type', 'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'Abandon Reason', 'Original File']], \n",
    "    mda_project4[['Mission ID', 'Service Name', 'Latitude Permanence', 'Longitude Permanence', 'Latitude Intervention', 'Longitude Intervention', 'Vector Type', 'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'Abandon Reason', 'Original File']], \n",
    "   mda_project5[['Mission ID', 'Service Name', 'Latitude Permanence', 'Longitude Permanence', 'Latitude Intervention', 'Longitude Intervention', 'Vector Type', 'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'Abandon Reason', 'Original File']]\n",
    "]\n",
    "cardiac_interventions = pd.concat(frames)\n",
    "\n",
    "# Replace values in the 'Vector Type' column\n",
    "cardiac_interventions['Vector Type'] = cardiac_interventions['Vector Type'].replace({'Ambulance': 'AMB', 'Ambulance Event': 'AMB', 'MUG Event': 'MUG'})\n",
    "\n",
    "## Correction of the latitude and longitude values\n",
    "# Define the desired ranges\n",
    "latitude_range = (48, 53)\n",
    "longitude_range = (1, 8)\n",
    "\n",
    "# Define a function to adjust latitude and longitude values\n",
    "def adjust_coordinate(value, coordinate_range):\n",
    "    if value < coordinate_range[0] or value > coordinate_range[1]:\n",
    "        return value / 10\n",
    "    return value\n",
    "\n",
    "# Apply the adjustment function to Latitude Permanence and Latitude Intervention\n",
    "while any((cardiac_interventions['Latitude Permanence'] < latitude_range[0]) | (cardiac_interventions['Latitude Permanence'] > latitude_range[1])):\n",
    "    cardiac_interventions['Latitude Permanence'] = cardiac_interventions['Latitude Permanence'].apply(lambda x: adjust_coordinate(x, latitude_range))\n",
    "    cardiac_interventions['Latitude Intervention'] = cardiac_interventions['Latitude Intervention'].apply(lambda x: adjust_coordinate(x, latitude_range))\n",
    "\n",
    "# Apply the adjustment function to Longitude Permanence and Longitude Intervention\n",
    "while any((cardiac_interventions['Longitude Permanence'] < longitude_range[0]) | (cardiac_interventions['Longitude Permanence'] > longitude_range[1])):\n",
    "    cardiac_interventions['Longitude Permanence'] = cardiac_interventions['Longitude Permanence'].apply(lambda x: adjust_coordinate(x, longitude_range))\n",
    "    cardiac_interventions['Longitude Intervention'] = cardiac_interventions['Longitude Intervention'].apply(lambda x: adjust_coordinate(x, longitude_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiac_interventions['T3_T0_difference_minutes'] = (cardiac_interventions['T3'] - cardiac_interventions['T0']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiac_interventions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing response times by service type????\n",
    "response_times_by_service = cardiac_interventions.groupby('Service Name')['T3_T0_difference_minutes'].mean()\n",
    "\n",
    "# Plotting\n",
    "sns.barplot(x=response_times_by_service.index, y=response_times_by_service.values)\n",
    "plt.ylabel('Average Response Time (minutes)')\n",
    "plt.title('Average Response Time by Service Type')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert latitude and longitude to floats\n",
    "cardiac_interventions['Latitude Intervention'] = pd.to_numeric(cardiac_interventions['Latitude Intervention'], errors='coerce')\n",
    "cardiac_interventions['Longitude Intervention'] = pd.to_numeric(cardiac_interventions['Longitude Intervention'], errors='coerce')\n",
    "\n",
    "# Drop rows where coordinates are NaN\n",
    "cardiac_interventions = cardiac_interventions.dropna(subset=['Latitude Intervention', 'Longitude Intervention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by location and count the occurrences\n",
    "location_counts = cardiac_interventions.groupby(['Latitude Intervention', 'Longitude Intervention']).size().reset_index(name='Counts')\n",
    "\n",
    "# Sort to find top locations with most events\n",
    "top_locations = location_counts.sort_values(by='Counts', ascending=False).head(10)\n",
    "print(top_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "map = folium.Map(location=[cardiac_interventions['Latitude Intervention'].mean(), cardiac_interventions['Longitude Intervention'].mean()], zoom_start=12)\n",
    "\n",
    "# Add markers for top hotspot locations\n",
    "for idx, row in top_locations.iterrows():\n",
    "    folium.CircleMarker([row['Latitude Intervention'], row['Longitude Intervention']],\n",
    "                        radius=row['Counts']/10, # this scales the circle sizes by count\n",
    "                        popup=f\"Count: {row['Counts']}\",\n",
    "                        color='red',\n",
    "                        fill=True,\n",
    "                        fill_color='red').add_to(map)\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis: longer response time is associated to high likelhood of death\n",
    "# Convert abandonment to binary \n",
    "cardiac_interventions['abandoned'] = cardiac_interventions['Abandon Reason'].notna()  # Assumes NaN where no abandonment\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cardiac_interventions['T3_T0_difference_minutes'].corr(cardiac_interventions['abandoned'])\n",
    "print(\"Correlation between response time and abandonment:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert abandonment reason to a binary variable\n",
    "cardiac_interventions['Abandon Binary'] = cardiac_interventions['Abandon Reason'].apply(lambda x: 1 if x == 'Overleden' else 0)\n",
    "\n",
    "# Features and target\n",
    "X = cardiac_interventions[['T3_T0_difference_minutes']].notna()  # or more features can be included\n",
    "y = cardiac_interventions['Abandon Binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split into training + validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then split the training + validation set into separate training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression classifier\n",
    "classifier = LogisticRegression(random_state = 42)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# making confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
